{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from time import time\n",
    "os.environ['TF_XLA_FLAGS'] = \"--tf_xla_auto_jit=fusible\"\n",
    "#os.environ['TF_XLA_FLAGS'] = \"--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit\"\n",
    "from tqdm.notebook import tqdm\n",
    "sys.path.append('..')\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow.compat.v1.keras.mixed_precision import experimental as mixed_precision\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices[1], 'GPU')\n",
    "\n",
    "#tf.keras.backend.set_floatx('float16')\n",
    "#policy = mixed_precision.Policy('mixed_float16')\n",
    "#mixed_precision.set_policy(policy)\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "import horovod.tensorflow as hvd\n",
    "hvd.init()\n",
    "\n",
    "from mask_rcnn.hyperparameters import dataset_params\n",
    "from mask_rcnn.hyperparameters import mask_rcnn_params\n",
    "from mask_rcnn import dataset_utils\n",
    "\n",
    "from mask_rcnn import anchors\n",
    "\n",
    "from mask_rcnn.models import fpn\n",
    "from mask_rcnn.models import heads\n",
    "from mask_rcnn.models import resnet\n",
    "\n",
    "from mask_rcnn.training import losses, learning_rates\n",
    "\n",
    "from mask_rcnn.ops import postprocess_ops\n",
    "from mask_rcnn.ops import roi_ops\n",
    "from mask_rcnn.ops import spatial_transform_ops\n",
    "from mask_rcnn.ops import training_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_pattern = '/workspace/shared_workspace/data/coco/tf_record/train*'\n",
    "MODELS = dict()\n",
    "batch_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params = dataset_params.get_data_params()\n",
    "params = mask_rcnn_params.default_config().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_params['batch_size'] = batch_size\n",
    "params['finetune_bn'] = False\n",
    "params['train_batch_size'] = batch_size\n",
    "params['l2_weight_decay'] = 1e-4\n",
    "params['init_learning_rate'] = 1e-4 * batch_size\n",
    "params['warmup_learning_rate'] = 1e-3 * batch_size\n",
    "params['warmup_steps'] = 500\n",
    "params['learning_rate_steps'] = [30000,40000]\n",
    "params['learning_rate_levels'] = [1e-4 * batch_size, 1e-5 * batch_size]\n",
    "params['momentum'] = 0.9\n",
    "params['use_batched_nms'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] INFO    : Using Dataset Sharding with Horovod\n"
     ]
    }
   ],
   "source": [
    "train_input_fn = dataset_utils.FastDataLoader(train_file_pattern, data_params)\n",
    "train_tdf = train_input_fn(data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-f1b1a4fdc42e>:1: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "tdf_iter = train_tdf.make_initializable_iterator()\n",
    "features, labels = tdf_iter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(features,  params, labels=None, is_training=True):\n",
    "    \"\"\"Builds the forward model graph.\"\"\"\n",
    "    model_outputs = {}\n",
    "    is_gpu_inference = not is_training and params['use_batched_nms']\n",
    "\n",
    "    batch_size, image_height, image_width, _ = features['images'].get_shape().as_list()\n",
    "\n",
    "    if 'source_ids' not in features:\n",
    "        features['source_ids'] = -1 * tf.ones([batch_size], dtype=tf.float32)\n",
    "\n",
    "    all_anchors = anchors.Anchors(params['min_level'], params['max_level'],\n",
    "                                  params['num_scales'], params['aspect_ratios'],\n",
    "                                  params['anchor_scale'],\n",
    "                                  (image_height, image_width))\n",
    "\n",
    "    MODELS[\"backbone\"] = resnet.Resnet_Model(\n",
    "        \"resnet50\",\n",
    "        data_format='channels_last',\n",
    "        trainable=is_training,\n",
    "        finetune_bn=params['finetune_bn']\n",
    "    )\n",
    "\n",
    "    backbone_feats = MODELS[\"backbone\"](\n",
    "        features['images'],\n",
    "        training=is_training,\n",
    "    )\n",
    "    MODELS[\"FPN\"] = fpn.FPNNetwork(params['min_level'], params['max_level'], trainable=is_training)\n",
    "    fpn_feats = MODELS[\"FPN\"](backbone_feats, training=is_training)\n",
    "\n",
    "    model_outputs.update({'fpn_features': fpn_feats})\n",
    "\n",
    "    def rpn_head_fn(features, min_level=2, max_level=6, num_anchors=3):\n",
    "        \"\"\"Region Proposal Network (RPN) for Mask-RCNN.\"\"\"\n",
    "        scores_outputs = dict()\n",
    "        box_outputs = dict()\n",
    "\n",
    "        MODELS[\"RPN_Heads\"] = heads.RPN_Head_Model(name=\"rpn_head\", num_anchors=num_anchors, trainable=is_training)\n",
    "\n",
    "        for level in range(min_level, max_level + 1):\n",
    "            scores_outputs[level], box_outputs[level] = MODELS[\"RPN_Heads\"](features[level], training=is_training)\n",
    "            scores_outputs[level] = tf.cast(scores_outputs[level], tf.float32)\n",
    "            box_outputs[level] = tf.cast(box_outputs[level], tf.float32)\n",
    "        return scores_outputs, box_outputs\n",
    "\n",
    "    rpn_score_outputs, rpn_box_outputs = rpn_head_fn(\n",
    "        features=fpn_feats,\n",
    "        min_level=params['min_level'],\n",
    "        max_level=params['max_level'],\n",
    "        num_anchors=len(params['aspect_ratios'] * params['num_scales'])\n",
    "    )\n",
    "    if is_training:\n",
    "        rpn_pre_nms_topn = params['train_rpn_pre_nms_topn']\n",
    "        rpn_post_nms_topn = params['train_rpn_post_nms_topn']\n",
    "        rpn_nms_threshold = params['train_rpn_nms_threshold']\n",
    "\n",
    "    else:\n",
    "        rpn_pre_nms_topn = params['test_rpn_pre_nms_topn']\n",
    "        rpn_post_nms_topn = params['test_rpn_post_nms_topn']\n",
    "        rpn_nms_threshold = params['test_rpn_nms_thresh']\n",
    "    \n",
    "    rpn_box_scores, rpn_box_rois = roi_ops.custom_multilevel_propose_rois(\n",
    "        scores_outputs=rpn_score_outputs,\n",
    "        box_outputs=rpn_box_outputs,\n",
    "        all_anchors=all_anchors,\n",
    "        image_info=features['image_info'],\n",
    "        rpn_pre_nms_topn=rpn_pre_nms_topn,\n",
    "        rpn_post_nms_topn=rpn_post_nms_topn,\n",
    "        rpn_nms_threshold=rpn_nms_threshold,\n",
    "        rpn_min_size=params['rpn_min_size']\n",
    "    )\n",
    "    if is_training:\n",
    "        rpn_box_rois = tf.stop_gradient(rpn_box_rois)\n",
    "        rpn_box_scores = tf.stop_gradient(rpn_box_scores)  # TODO Jonathan: Unused => Shall keep ?\n",
    "\n",
    "        # Sampling\n",
    "        box_targets, class_targets, rpn_box_rois, proposal_to_label_map = training_ops.proposal_label_op(\n",
    "            rpn_box_rois,\n",
    "            labels['gt_boxes'],\n",
    "            labels['gt_classes'],\n",
    "            batch_size_per_im=params['batch_size_per_im'],\n",
    "            fg_fraction=params['fg_fraction'],\n",
    "            fg_thresh=params['fg_thresh'],\n",
    "            bg_thresh_hi=params['bg_thresh_hi'],\n",
    "            bg_thresh_lo=params['bg_thresh_lo']\n",
    "        )\n",
    "    # Performs multi-level RoIAlign.\n",
    "    box_roi_features = spatial_transform_ops.multilevel_crop_and_resize(\n",
    "        features=fpn_feats,\n",
    "        boxes=rpn_box_rois,\n",
    "        output_size=7,\n",
    "        is_gpu_inference=is_gpu_inference\n",
    "    )\n",
    "\n",
    "    MODELS[\"Box_Head\"] = heads.Box_Head_Model(\n",
    "        num_classes=params['num_classes'],\n",
    "        mlp_head_dim=params['fast_rcnn_mlp_head_dim'],\n",
    "        trainable=is_training\n",
    "    )\n",
    "    class_outputs, box_outputs, _ = MODELS[\"Box_Head\"](inputs=box_roi_features)\n",
    "    if not is_training:\n",
    "        generate_detections_fn = postprocess_ops.generate_detections_gpu\n",
    "        detections = generate_detections_fn(\n",
    "            class_outputs=class_outputs,\n",
    "            box_outputs=box_outputs,\n",
    "            anchor_boxes=rpn_box_rois,\n",
    "            image_info=features['image_info'],\n",
    "            pre_nms_num_detections=params['test_rpn_post_nms_topn'],\n",
    "            post_nms_num_detections=params['test_detections_per_image'],\n",
    "            nms_threshold=params['test_nms'],\n",
    "            bbox_reg_weights=params['bbox_reg_weights']\n",
    "        )\n",
    "        model_outputs.update({\n",
    "            'num_detections': detections[0],\n",
    "            'detection_boxes': detections[1],\n",
    "            'detection_classes': detections[2],\n",
    "            'detection_scores': detections[3],\n",
    "        })\n",
    "    else:  # is training\n",
    "        encoded_box_targets = training_ops.encode_box_targets(\n",
    "            boxes=rpn_box_rois,\n",
    "            gt_boxes=box_targets,\n",
    "            gt_labels=class_targets,\n",
    "            bbox_reg_weights=params['bbox_reg_weights']\n",
    "        )\n",
    "\n",
    "        model_outputs.update({\n",
    "            'rpn_score_outputs': rpn_score_outputs,\n",
    "            'rpn_box_outputs': rpn_box_outputs,\n",
    "            'class_outputs': tf.cast(class_outputs, tf.float32),\n",
    "            'box_outputs': tf.cast(box_outputs, tf.float32),\n",
    "            'class_targets': class_targets,\n",
    "            'box_targets': encoded_box_targets,\n",
    "            'box_rois': rpn_box_rois,\n",
    "        })\n",
    "    # Mask sampling\n",
    "    if not is_training:\n",
    "        selected_box_rois = model_outputs['detection_boxes']\n",
    "        class_indices = model_outputs['detection_classes']\n",
    "\n",
    "        # If using GPU for inference, delay the cast until when Gather ops show up\n",
    "        # since GPU inference supports float point better.\n",
    "        # TODO(laigd): revisit this when newer versions of GPU libraries is\n",
    "        # released.\n",
    "        if not params['use_batched_nms']:\n",
    "            class_indices = tf.cast(class_indices, dtype=tf.int32)\n",
    "\n",
    "    else:\n",
    "        selected_class_targets, selected_box_targets, \\\n",
    "        selected_box_rois, proposal_to_label_map = training_ops.select_fg_for_masks(\n",
    "            class_targets=class_targets,\n",
    "            box_targets=box_targets,\n",
    "            boxes=rpn_box_rois,\n",
    "            proposal_to_label_map=proposal_to_label_map,\n",
    "            max_num_fg=int(params['batch_size_per_im'] * params['fg_fraction'])\n",
    "        )\n",
    "\n",
    "        class_indices = tf.cast(selected_class_targets, dtype=tf.int32)\n",
    "\n",
    "    mask_roi_features = spatial_transform_ops.multilevel_crop_and_resize(\n",
    "        features=fpn_feats,\n",
    "        boxes=selected_box_rois,\n",
    "        output_size=14,\n",
    "        is_gpu_inference=is_gpu_inference\n",
    "    )\n",
    "\n",
    "    MODELS[\"Mask_Head\"] = heads.Mask_Head_Model(\n",
    "        class_indices,\n",
    "        num_classes=params['num_classes'],\n",
    "        mrcnn_resolution=params['mrcnn_resolution'],\n",
    "        is_gpu_inference=is_gpu_inference,\n",
    "        trainable=is_training,\n",
    "        name=\"mask_head\"\n",
    "    )\n",
    "\n",
    "    mask_outputs = MODELS[\"Mask_Head\"](inputs=mask_roi_features)\n",
    "    \n",
    "    if is_training:\n",
    "        mask_targets = training_ops.get_mask_targets(\n",
    "\n",
    "            fg_boxes=selected_box_rois,\n",
    "            fg_proposal_to_label_map=proposal_to_label_map,\n",
    "            fg_box_targets=selected_box_targets,\n",
    "            mask_gt_labels=labels['cropped_gt_masks'],\n",
    "            output_size=params['mrcnn_resolution']\n",
    "        )\n",
    "\n",
    "        model_outputs.update({\n",
    "            'mask_outputs': tf.cast(mask_outputs, tf.float32),\n",
    "            'mask_targets': mask_targets,\n",
    "            'selected_class_targets': selected_class_targets,\n",
    "        })\n",
    "\n",
    "    else:\n",
    "        model_outputs.update({\n",
    "            'detection_masks': tf.nn.sigmoid(mask_outputs),\n",
    "        })\n",
    "\n",
    "    return model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(learning_rate, params):\n",
    "    \"\"\"Creates optimized based on the specified flags.\"\"\"\n",
    "\n",
    "    optimizer = tf.compat.v1.train.MomentumOptimizer(learning_rate, momentum=params['momentum'])\n",
    "\n",
    "    optimizer = hvd.DistributedOptimizer(\n",
    "        optimizer,\n",
    "        name=None,\n",
    "        device_dense='/gpu:0',\n",
    "        device_sparse='',\n",
    "        compression=hvd.Compression.fp16,\n",
    "        sparse_as_dense=False\n",
    "    )\n",
    "    \n",
    "    loss_scale = tf.train.experimental.DynamicLossScale(\n",
    "        initial_loss_scale=(2 ** 12),\n",
    "        increment_period=2000,\n",
    "        multiplier=2.0\n",
    "    )\n",
    "    optimizer = tf.compat.v1.train.experimental.MixedPrecisionLossScaleOptimizer(optimizer, loss_scale=loss_scale)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(features,  params, labels=None, is_training=True):\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    model_outputs = forward(features, params, labels, is_training)\n",
    "    #model_outputs['class_targets'] = tf.cast(model_outputs['class_targets'])\n",
    "    model_outputs.update({\n",
    "        'source_id': features['source_ids'],\n",
    "        'image_info': features['image_info'],\n",
    "    })\n",
    "    if not is_training:\n",
    "        predictions = {}\n",
    "        try:\n",
    "            model_outputs['orig_images'] = features['orig_images']\n",
    "        except KeyError:\n",
    "            pass\n",
    "        model_outputs.pop('fpn_features', None)\n",
    "        predictions.update(model_outputs)\n",
    "        return model_outputs\n",
    "    total_rpn_loss, rpn_score_loss, rpn_box_loss = losses.rpn_loss(\n",
    "        score_outputs=model_outputs['rpn_score_outputs'],\n",
    "        box_outputs=model_outputs['rpn_box_outputs'],\n",
    "        labels=labels,\n",
    "        params=params\n",
    "    )\n",
    "    total_fast_rcnn_loss, fast_rcnn_class_loss, fast_rcnn_box_loss = losses.fast_rcnn_loss(\n",
    "        class_outputs=model_outputs['class_outputs'],\n",
    "        box_outputs=model_outputs['box_outputs'],\n",
    "        class_targets=model_outputs['class_targets'],\n",
    "        box_targets=model_outputs['box_targets'],\n",
    "        params=params\n",
    "    )\n",
    "    mask_loss = losses.mask_rcnn_loss(\n",
    "        mask_outputs=model_outputs['mask_outputs'],\n",
    "        mask_targets=model_outputs['mask_targets'],\n",
    "        select_class_targets=model_outputs['selected_class_targets'],\n",
    "        params=params\n",
    "    )\n",
    "    trainable_variables = list(itertools.chain.from_iterable([model.trainable_variables for model in MODELS.values()]))\n",
    "    l2_regularization_loss = params['l2_weight_decay'] * tf.add_n([\n",
    "        tf.nn.l2_loss(v)\n",
    "        for v in trainable_variables\n",
    "        if not any([pattern in v.name for pattern in [\"batch_normalization\", \"bias\", \"beta\"]])\n",
    "    ])\n",
    "\n",
    "    total_loss = total_rpn_loss + total_fast_rcnn_loss + mask_loss + l2_regularization_loss\n",
    "    learning_rate = learning_rates.step_learning_rate_with_linear_warmup(\n",
    "        global_step=global_step,\n",
    "        init_learning_rate=params['init_learning_rate'],\n",
    "        warmup_learning_rate=params['warmup_learning_rate'],\n",
    "        warmup_steps=params['warmup_steps'],\n",
    "        learning_rate_levels=params['learning_rate_levels'],\n",
    "        learning_rate_steps=params['learning_rate_steps']\n",
    "    )\n",
    "    optimizer = create_optimizer(learning_rate, params)\n",
    "    grads_and_vars = optimizer.compute_gradients(total_loss, trainable_variables, colocate_gradients_with_ops=True)\n",
    "\n",
    "    gradients, variables = zip(*grads_and_vars)\n",
    "    grads_and_vars = []\n",
    "\n",
    "    # Special treatment for biases (beta is named as bias in reference model)\n",
    "    # Reference: https://github.com/ddkang/Detectron/blob/80f3295308/lib/modeling/optimizer.py#L109\n",
    "    for grad, var in zip(gradients, variables):\n",
    "\n",
    "        if grad is not None and any([pattern in var.name for pattern in [\"bias\", \"beta\"]]):\n",
    "            grad = 2.0 * grad\n",
    "\n",
    "        grads_and_vars.append((grad, var))\n",
    "\n",
    "    train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "    return train_op, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "train_op, total_loss = model(features, params, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_vars = [op.name for op in tf.get_default_graph().get_operations() \\\n",
    "              if op.op_def and 'resnet50/conv2d_14' in op.name]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='resnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_assigment_map(prefix=None, skip_variables_regex=None):\n",
    "    \"\"\"Generate assigment map for loading checkpoints.\"\"\"\n",
    "    all_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=prefix)\n",
    "    if not prefix:\n",
    "        prefix = ''\n",
    "    assignment_map = {}\n",
    "    for var in all_vars:\n",
    "        var_name = var.name\n",
    "        if (\n",
    "                var_name[-11:] in \"/Momentum:0\" or\n",
    "                var_name[-11:] in \"/Adadelta:0\" or\n",
    "                var_name[-13:] in \"/Adadelta_1:0\" or\n",
    "                var_name[-7:] in \"/Adam:0\" or\n",
    "                var_name[-9:] in \"/Adam_1:0\" or\n",
    "                var_name[-10:] in \"/Adagrad:0\" or\n",
    "                var_name[-10:] in \"/RMSProp:0\" or\n",
    "                var_name[-12:] in \"/RMSProp_1:0\" or\n",
    "                var_name[-16:] in \"/LARSOptimizer:0\"\n",
    "        ):\n",
    "            continue\n",
    "        # Trim the index of the variable.\n",
    "        if ':' in var_name:\n",
    "            var_name = var_name[:var_name.rindex(':')]\n",
    "        if skip_variables_regex and re.match(skip_variables_regex, var_name[len(prefix):]):\n",
    "            continue\n",
    "        assignment_map[var_name[len(prefix):]] = var\n",
    "        # assignment_map[var_name] = var\n",
    "    return assignment_map\n",
    "\n",
    "def assign_from_checkpoint(model_path, var_list, ignore_missing_vars=False):\n",
    "    \"\"\"Creates an operation to assign specific variables from a checkpoint.\n",
    "    Args:\n",
    "    model_path: The full path to the model checkpoint. To get latest checkpoint\n",
    "      use `model_path = tf.train.latest_checkpoint(checkpoint_dir)`\n",
    "    var_list: A list of (possibly partitioned) `Variable` objects or a\n",
    "      dictionary mapping names in the checkpoint to the corresponding variables\n",
    "      or list of variables to initialize from that checkpoint value. For\n",
    "      partitioned Variables, the name in the checkpoint must be the full\n",
    "      variable, not the name of the partitioned variable, eg. \"my_var\" rather\n",
    "      than \"my_var/part_4\". If empty, returns no_op(), {}.\n",
    "    ignore_missing_vars: Boolean, if True ignore variables missing in the\n",
    "      checkpoint with a warning instead of failing.\n",
    "    Returns:\n",
    "    the restore_op and the feed_dict that need to be run to restore var_list.\n",
    "    Raises:\n",
    "    ValueError: If `ignore_missing_vars` is False and the checkpoint specified\n",
    "        at `model_path` is missing one of the variables in `var_list`.\n",
    "  \"\"\"\n",
    "    # Normalize var_list into a dictionary mapping names in the\n",
    "    # checkpoint to the list of variables to initialize from that\n",
    "    # checkpoint variable. Sliced (including partitioned) variables will\n",
    "    # end up under the same key.\n",
    "    grouped_vars = {}\n",
    "    if isinstance(var_list, (tuple, list)):\n",
    "        for var in var_list:\n",
    "            ckpt_name = get_variable_full_name(var)\n",
    "            if ckpt_name not in grouped_vars:\n",
    "                grouped_vars[ckpt_name] = []\n",
    "            grouped_vars[ckpt_name].append(var)\n",
    "\n",
    "    else:\n",
    "        for ckpt_name, value in var_list.items():\n",
    "            if isinstance(value, (tuple, list)):\n",
    "                grouped_vars[ckpt_name] = value\n",
    "            else:\n",
    "                grouped_vars[ckpt_name] = [value]\n",
    "\n",
    "    # Read each checkpoint entry. Create a placeholder variable and\n",
    "    # add the (possibly sliced) data from the checkpoint to the feed_dict.\n",
    "    reader = tf.compat.v1.train.NewCheckpointReader(model_path)\n",
    "    feed_dict = {}\n",
    "    assign_ops = []\n",
    "    for ckpt_name in grouped_vars:\n",
    "        if not reader.has_tensor(ckpt_name):\n",
    "            log_str = 'Checkpoint is missing variable [%s]' % ckpt_name\n",
    "            if ignore_missing_vars:\n",
    "                logging.warning(log_str)\n",
    "                continue\n",
    "            else:\n",
    "                raise ValueError(log_str)\n",
    "        ckpt_value = reader.get_tensor(ckpt_name)\n",
    "\n",
    "        for var in grouped_vars[ckpt_name]:\n",
    "            placeholder_tensor = tf.compat.v1.placeholder(\n",
    "                dtype=var.dtype.base_dtype,\n",
    "                shape=var.get_shape(),\n",
    "                name='placeholder/' + var.op.name\n",
    "            )\n",
    "\n",
    "            assign_ops.append(var.assign(placeholder_tensor))\n",
    "\n",
    "            if not var._save_slice_info:\n",
    "                if var.get_shape() != ckpt_value.shape:\n",
    "                    raise ValueError(\n",
    "                        'Total size of new array must be unchanged for %s '\n",
    "                        'lh_shape: [%s], rh_shape: [%s]' %\n",
    "                        (ckpt_name, str(ckpt_value.shape), str(var.get_shape())))\n",
    "\n",
    "                feed_dict[placeholder_tensor] = ckpt_value.reshape(ckpt_value.shape)\n",
    "\n",
    "            else:\n",
    "                slice_dims = zip(var._save_slice_info.var_offset,\n",
    "                                 var._save_slice_info.var_shape)\n",
    "\n",
    "                slice_dims = [(start, start + size) for (start, size) in slice_dims]\n",
    "                slice_dims = [slice(*x) for x in slice_dims]\n",
    "\n",
    "                slice_value = ckpt_value[slice_dims]\n",
    "                slice_value = slice_value.reshape(var._save_slice_info.var_shape)\n",
    "\n",
    "                feed_dict[placeholder_tensor] = slice_value\n",
    "\n",
    "    print_op = tf.print(\n",
    "        \"[GPU %02d] Restoring pretrained weights (%d Tensors) from: %s\" % (\n",
    "            hvd.rank(),\n",
    "            len(assign_ops),\n",
    "            model_path\n",
    "        ),\n",
    "        output_stream=sys.stdout\n",
    "    )\n",
    "\n",
    "    with tf.control_dependencies([print_op]):\n",
    "        assign_op = tf.group(*assign_ops)\n",
    "\n",
    "    return assign_op, feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = build_assigment_map('resnet50/')\n",
    "checkpoint_file = tf.train.latest_checkpoint('/model/resnet/resnet-nhwc-2018-02-07/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_init_op, _init_feed_dict = assign_from_checkpoint(checkpoint_file, var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1fba04b58f49d383b9efb5f3bfa67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU 00] Restoring pretrained weights (265 Tensors) from: /model/resnet/resnet-nhwc-2018-02-07/model.ckpt-112603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var_initializer = tf.global_variables_initializer()\n",
    "progressbar = tqdm(range(10000))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(_init_op, _init_feed_dict)\n",
    "    sess.run(tdf_iter.initializer)\n",
    "    sess.run(var_initializer)\n",
    "    for i in progressbar:\n",
    "        op, loss = sess.run((train_op, total_loss))\n",
    "        progressbar.set_description(\"Loss: {0:.4f}\".format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['mask_outputs'][2].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
