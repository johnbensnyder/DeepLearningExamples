{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from time import time\n",
    "os.environ['TF_XLA_FLAGS'] = \"--tf_xla_auto_jit=fusible\"\n",
    "#os.environ['TF_XLA_FLAGS'] = \"--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit\"\n",
    "from tqdm.notebook import tqdm\n",
    "sys.path.append('..')\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(physical_devices, 'GPU')\n",
    "\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "import horovod.tensorflow as hvd\n",
    "hvd.init()\n",
    "\n",
    "from mask_rcnn.hyperparameters import dataset_params\n",
    "from mask_rcnn.hyperparameters import mask_rcnn_params\n",
    "from mask_rcnn import dataset_utils\n",
    "from simple_model import load_weights\n",
    "\n",
    "from mask_rcnn.models import resnet\n",
    "from mask_rcnn.models import fpn\n",
    "\n",
    "train_file_pattern = '/workspace/shared_workspace/data/coco/tf_record/train*'\n",
    "MODELS = dict()\n",
    "batch_size = 1\n",
    "\n",
    "data_params = dataset_params.get_data_params()\n",
    "params = mask_rcnn_params.default_config().values()\n",
    "\n",
    "data_params['batch_size'] = batch_size\n",
    "params['finetune_bn'] = False\n",
    "params['train_batch_size'] = batch_size\n",
    "params['l2_weight_decay'] = 1e-4\n",
    "params['init_learning_rate'] = 1e-4 * batch_size\n",
    "params['warmup_learning_rate'] = 1e-3 * batch_size\n",
    "params['warmup_steps'] = 500\n",
    "params['learning_rate_steps'] = [30000,40000]\n",
    "params['learning_rate_levels'] = [1e-4 * batch_size, 1e-5 * batch_size]\n",
    "params['momentum'] = 0.9\n",
    "params['use_batched_nms'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] INFO    : Using Dataset Sharding with Horovod\n"
     ]
    }
   ],
   "source": [
    "train_input_fn = dataset_utils.FastDataLoader(train_file_pattern, data_params)\n",
    "train_tdf = train_input_fn(data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-f1b1a4fdc42e>:1: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n"
     ]
    }
   ],
   "source": [
    "tdf_iter = train_tdf.make_initializable_iterator()\n",
    "features, labels = tdf_iter.get_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] INFO    : Using Dataset Sharding with Horovod\n",
      "[MaskRCNN] INFO    : Using Dataset Sharding with Horovod\n"
     ]
    }
   ],
   "source": [
    "train_input_fn_0 = dataset_utils.FastDataLoader(train_file_pattern, data_params)\n",
    "train_tdf_0 = train_input_fn(data_params)\n",
    "\n",
    "train_input_fn_1 = dataset_utils.FastDataLoader(train_file_pattern, data_params)\n",
    "train_tdf_1 = train_input_fn(data_params)\n",
    "\n",
    "def map0(features, labels):\n",
    "    features['images'] = features['images'][:,:,:672,:]\n",
    "    return features, labels\n",
    "    \n",
    "def map1(features, labels):\n",
    "    features['images'] = features['images'][:,:,672:,:]\n",
    "    return features, labels\n",
    "\n",
    "train_tdf_0 = train_tdf_0.map(map0, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "                       .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "train_tdf_1 = train_tdf_1.map(map1, num_parallel_calls=tf.data.experimental.AUTOTUNE) \\\n",
    "                       .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_iter_0 = train_tdf_0.make_initializable_iterator()\n",
    "features_0, labels_0 = tdf_iter_0.get_next()\n",
    "\n",
    "tdf_iter_1 = train_tdf_1.make_initializable_iterator()\n",
    "features_1, labels_1 = tdf_iter_0.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backbone(features_0, features_1,  params, labels=None, is_training=True):\n",
    "    \n",
    "    with tf.device('/gpu:0'):\n",
    "        MODELS[\"backbone_0\"] = resnet.Resnet_Model(\n",
    "            \"resnet50\",\n",
    "            data_format='channels_last',\n",
    "            trainable=is_training,\n",
    "            finetune_bn=params['finetune_bn']\n",
    "        )\n",
    "        MODELS[\"FPN_0\"] = fpn.FPNNetwork(params['min_level'], params['max_level'], trainable=is_training)\n",
    "        backbone_feats_0 = MODELS[\"backbone_0\"](\n",
    "            features_0['images'],\n",
    "            training=is_training,\n",
    "        )\n",
    "        fpn_feats_0 = MODELS[\"FPN_0\"](backbone_feats_0, training=is_training)\n",
    "    \n",
    "    with tf.device('/gpu:6'):\n",
    "        MODELS[\"backbone_1\"] = resnet.Resnet_Model(\n",
    "            \"resnet50\",\n",
    "            data_format='channels_last',\n",
    "            trainable=is_training,\n",
    "            finetune_bn=params['finetune_bn']\n",
    "        )\n",
    "        MODELS[\"FPN_1\"] = fpn.FPNNetwork(params['min_level'], params['max_level'], trainable=is_training)\n",
    "        backbone_feats_1 = MODELS[\"backbone_1\"](\n",
    "            features_1['images'],\n",
    "            training=is_training,\n",
    "        )\n",
    "        fpn_feats_1 = MODELS[\"FPN_1\"](backbone_feats_1, training=is_training)\n",
    "    \n",
    "    with tf.device('/gpu:0'):\n",
    "        fpn_feats_0 = {i: tf.concat([j,k], axis=2) for (i,j),k \\\n",
    "             in zip(fpn_feats_0.items(), fpn_feats_1.values())}\n",
    "    \n",
    "    with tf.device('/gpu:1'):\n",
    "        fpn_feats_1 = {i: tf.concat([j,k], axis=2) for (i,j),k \\\n",
    "             in zip(fpn_feats_0.items(), fpn_feats_1.values())}\n",
    "    \n",
    "    '''MODELS[\"backbone\"] = resnet.Resnet_Model(\n",
    "            \"resnet50\",\n",
    "            data_format='channels_last',\n",
    "            trainable=is_training,\n",
    "            finetune_bn=params['finetune_bn']\n",
    "        )\n",
    "    MODELS[\"FPN\"] = fpn.FPNNetwork(params['min_level'], params['max_level'], trainable=is_training)\n",
    "        \n",
    "    backbone_feats = MODELS[\"backbone\"](\n",
    "            features['images'],\n",
    "            training=is_training,\n",
    "        )\n",
    "    fpn_feats = MODELS[\"FPN\"](backbone_feats, training=is_training)'''\n",
    "    return fpn_feats_0, fpn_feats_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn_feats = backbone(features_0, features_1, params, labels_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = load_weights.build_assigment_map('resnet50/')\n",
    "checkpoint_file = tf.train.latest_checkpoint('/model/resnet/resnet-nhwc-2018-02-07/')\n",
    "_init_op, _init_feed_dict = load_weights.assign_from_checkpoint(checkpoint_file, var_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a87a011c3e440c9af28a800c419f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU 00] Restoring pretrained weights (265 Tensors) from: /model/resnet/resnet-nhwc-2018-02-07/model.ckpt-112603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var_initializer = tf.global_variables_initializer()\n",
    "progressbar = tqdm(range(10000))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(_init_op, _init_feed_dict)\n",
    "    sess.run(tdf_iter.initializer)\n",
    "    sess.run(tdf_iter_0.initializer)\n",
    "    sess.run(tdf_iter_1.initializer)\n",
    "    sess.run(var_initializer)\n",
    "    for i in progressbar:\n",
    "        result = sess.run(fpn_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fpn_feats_0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-e3b6e7b41b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfpn_feats_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fpn_feats_0' is not defined"
     ]
    }
   ],
   "source": [
    "fpn_feats_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: <tf.Tensor 'fpn_1/post_hoc_d5/BiasAdd:0' shape=(6, 26, 21, 256) dtype=float32>,\n",
       " 4: <tf.Tensor 'fpn_1/post_hoc_d4/BiasAdd:0' shape=(6, 52, 42, 256) dtype=float32>,\n",
       " 3: <tf.Tensor 'fpn_1/post_hoc_d3/BiasAdd:0' shape=(6, 104, 84, 256) dtype=float32>,\n",
       " 2: <tf.Tensor 'fpn_1/post_hoc_d2/BiasAdd:0' shape=(6, 208, 168, 256) dtype=float32>,\n",
       " 6: <tf.Tensor 'fpn_1/p6/MaxPool:0' shape=(6, 13, 11, 256) dtype=float32>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_feats_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: <tf.Tensor 'concat:0' shape=(6, 26, 42, 256) dtype=float32>,\n",
       " 4: <tf.Tensor 'concat_1:0' shape=(6, 52, 84, 256) dtype=float32>,\n",
       " 3: <tf.Tensor 'concat_2:0' shape=(6, 104, 168, 256) dtype=float32>,\n",
       " 2: <tf.Tensor 'concat_3:0' shape=(6, 208, 336, 256) dtype=float32>,\n",
       " 6: <tf.Tensor 'concat_4:0' shape=(6, 13, 22, 256) dtype=float32>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
