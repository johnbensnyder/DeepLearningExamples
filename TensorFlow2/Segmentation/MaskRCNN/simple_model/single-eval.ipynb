{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "os.environ['TF_XLA_FLAGS'] = \"--tf_xla_auto_jit=fusible\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "import horovod.tensorflow as hvd\n",
    "hvd.init()\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[hvd.rank()], True)\n",
    "tf.config.set_visible_devices(physical_devices[hvd.rank()], 'GPU')\n",
    "devices = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "#policy = mixed_precision.Policy('mixed_float16')\n",
    "#mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "#import GPUtil\n",
    "from mask_rcnn.tf2_model import MaskRCNN\n",
    "from mask_rcnn.hyperparameters import dataset_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask_rcnn.tf2_model import MaskRCNN\n",
    "from mask_rcnn.hyperparameters import dataset_params\n",
    "from mask_rcnn.hyperparameters import mask_rcnn_params\n",
    "from mask_rcnn import dataset_utils\n",
    "from mask_rcnn.training import losses, learning_rates\n",
    "from simple_model.tf2 import weight_loader, train, scheduler\n",
    "from simple_model import model_v2\n",
    "from evaluation import compute_coco_eval_metric_nonestimator, process_prediction_for_eval\n",
    "\n",
    "train_file_pattern = '/home/ubuntu/tfr_anchor/train*'\n",
    "eval_file_pattern = '/home/ubuntu/tfr_anchor/val*'\n",
    "batch_size = 4\n",
    "global_batch_size = batch_size * hvd.size()\n",
    "images = 118287\n",
    "steps_per_epoch = images//global_batch_size\n",
    "train_data_params = dataset_params.get_data_params()\n",
    "eval_data_params = dataset_params.get_data_params()\n",
    "params = mask_rcnn_params.default_config().values()\n",
    "train_data_params['batch_size'] = batch_size\n",
    "eval_data_params['batch_size'] = 1\n",
    "params['finetune_bn'] = False\n",
    "params['train_batch_size'] = batch_size\n",
    "params['l2_weight_decay'] = 1e-4\n",
    "params['init_learning_rate'] = 2e-3 * global_batch_size\n",
    "params['warmup_learning_rate'] = 2e-4 * global_batch_size\n",
    "params['warmup_steps'] = 4096//global_batch_size\n",
    "params['learning_rate_steps'] = [steps_per_epoch * 9, steps_per_epoch * 11]\n",
    "params['learning_rate_levels'] = [2e-4 * global_batch_size, 2e-5 * global_batch_size]\n",
    "params['momentum'] = 0.9\n",
    "params['use_batched_nms'] = False\n",
    "params['use_custom_box_proposals_op'] = True\n",
    "params['amp'] = True\n",
    "params['include_groundtruth_in_features'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] INFO    : Using Dataset Sharding with Horovod\n"
     ]
    }
   ],
   "source": [
    "eval_data_params = dataset_params.get_data_params()\n",
    "eval_data_params['batch_size'] = 1\n",
    "\n",
    "eval_loader = dataset_utils.FastDataLoader(eval_file_pattern, eval_data_params)\n",
    "eval_tdf = eval_loader(eval_data_params)\n",
    "eval_tdf = eval_tdf.apply(tf.data.experimental.prefetch_to_device(devices[0].name, \n",
    "                                                                    buffer_size=tf.data.experimental.AUTOTUNE))\n",
    "eval_iter = iter(eval_tdf)\n",
    "\n",
    "mask_rcnn = model_v2.MRCNN(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_rcnn.sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_weights() missing 1 required positional argument: 'filepath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-79f5ede8731a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask_rcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: load_weights() missing 1 required positional argument: 'filepath'"
     ]
    }
   ],
   "source": [
    "mask_rcnn.load_weights()\n",
    "@tf.function\n",
    "def pred(features, params):\n",
    "    out = mask_rcnn(features, None, params, is_training=False)\n",
    "    out['image_info'] = features['image_info']\n",
    "    out['source_id'] = features['source_ids']\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_json_file=\"/home/ubuntu/nv_tfrecords/annotations/instances_val2017.json\"\n",
    "eval_steps = 5000\n",
    "progressbar_eval = tqdm(range(eval_steps))\n",
    "worker_predictions = dict()    \n",
    "if hvd.rank()==0:\n",
    "    print(\"Beginning eval\")\n",
    "    progressbar_eval = tqdm(range(eval_steps))\n",
    "else:\n",
    "    progressbar_eval = range(eval_steps)\n",
    "\n",
    "for i in progressbar_eval:\n",
    "    features_val, _ = next(val_iter)\n",
    "    out = pred(features_val, params)\n",
    "    out = process_prediction_for_eval(out)\n",
    "\n",
    "    for k, v in out.items():\n",
    "        if k not in worker_predictions:\n",
    "            worker_predictions[k] = [v]\n",
    "        else:\n",
    "            worker_predictions[k].append(v)\n",
    "\n",
    "compute_coco_eval_metric_nonestimator(worker_predictions, annotation_json_file=val_json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_latest_p37)",
   "language": "python",
   "name": "conda_tensorflow2_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
